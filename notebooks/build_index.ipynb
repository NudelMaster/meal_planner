{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5821812d",
   "metadata": {},
   "source": [
    "# Necessary imports for building Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe94a978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting necessary imports, if interrupted midway restart kernel\n",
      "Finished imports\n"
     ]
    }
   ],
   "source": [
    "print(\"getting necessary imports, if interrupted midway restart kernel\")\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "print(\"Finished imports\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19fabf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 'recipes_for_embeddings.jsonl'...\n",
      "Example document: {'title': '\"Adult\" Pimiento Cheese ', 'text_for_embedding': 'Ingredients: a - jar diced pimientos, coarsely grated sharp cheddar, crackers, crudits, or large garlic cloves, to mayonnaise, toasted baguette. Recipe: \"Adult\" Pimiento Cheese'}\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the Data\n",
    "# Assuming the data is in a file named 'recipes_for_embeddings.jsonl' (JSON Lines format)\n",
    "data = []\n",
    "print(f\"Loading data from 'recipes_for_embeddings.jsonl'...\")\n",
    "assert os.path.exists('recipes_for_embeddings.jsonl'), \"Data file not found!\"\n",
    "with open('recipes_for_embeddings.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "print(f\"Example document: {data[0]}\")\n",
    "\n",
    "# Separating text for embedding and metadata (to retrieve later)\n",
    "documents = [d['text_for_embedding'] for d in data]\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b900e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalizing embedding model, using SentenceTransformer...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b159944d494954b8c19de9992be7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings shape: (18222, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initalizing embedding model, using SentenceTransformer...\")\n",
    "# 2. Initialize Embedding Model\n",
    "# We use a dedicated embedding model (not Qwen itself) for vectorization\n",
    "embed_model = SentenceTransformer('BAAI/bge-m3') # State-of-the-art open embedding model\n",
    "\n",
    "# 3. Generate Embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "recipe_embeddings = embed_model.encode(documents, convert_to_tensor=False, show_progress_bar=True)\n",
    "recipe_embeddings = np.array(recipe_embeddings).astype('float32')\n",
    "print(f\"Generated embeddings shape: {recipe_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e6f64b",
   "metadata": {},
   "source": [
    "## Normalize the vectors and create FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb4aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing vectors\n",
      "Creating Faiss index...\n",
      "Indexed 18222 documents with Cosine Similarity.\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalizing vectors\")\n",
    "# Normalize with respect to euclidean norm\n",
    "faiss.normalize_L2(recipe_embeddings)\n",
    "\n",
    "print(\"Creating Faiss index...\")\n",
    "# 4. Create FAISS Index\n",
    "\n",
    "dimension = recipe_embeddings.shape[1]\n",
    "# Switched from L2 to cosine similarity, for normalized vectors dot product becomes exactly cosine similarity\n",
    "index = faiss.IndexFlatIP(dimension) \n",
    "\n",
    "index.add(recipe_embeddings)\n",
    "\n",
    "print(f\"Indexed {index.ntotal} documents with Cosine Similarity.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "470244c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Faiss index to 'recipe_index.faiss'\n"
     ]
    }
   ],
   "source": [
    "# 5. Save the Index\n",
    "faiss.write_index(index, \"recipe_index.faiss\")\n",
    "print(\"Saved Faiss index to 'recipe_index.faiss'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2932688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meal_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
