{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, InferenceClientModel, Tool, DuckDuckGoSearchTool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langfuse import get_client\n",
    "from huggingface_hub import notebook_login\n",
    "import time\n",
    "import functools\n",
    "notebook_login()\n",
    "load_dotenv()\n",
    "angfuse_key = os.getenv('ANGFUSE_SECRET_KEY')\n",
    "model_id = \"Qwen/Qwen2.5-14B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_llm_call(func):\n",
    "    \"\"\"\n",
    "    A standard Python decorator that retries the decorated function \n",
    "    if the LLM server disconnects or returns a 503/404/Connection error.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        max_retries = 5\n",
    "        base_wait_time = 2  # Start with 2 seconds\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Attempt to execute the decorated method (e.g., forward)\n",
    "                return func(*args, **kwargs)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                \n",
    "                # Check for common server-side transient errors\n",
    "                # We also catch \"404\" specifically because sometimes routers momentarily lose the model\n",
    "                is_transient = (\n",
    "                    \"503\" in error_msg or \n",
    "                    \"Service Temporarily Unavailable\" in error_msg or \n",
    "                    \"Connection error\" in error_msg or\n",
    "                    \"404\" in error_msg  # Sometimes helpful for momentary router glitches\n",
    "                )\n",
    "                \n",
    "                if is_transient:\n",
    "                    wait_time = base_wait_time * (2 ** attempt) # Exponential backoff: 2, 4, 8...\n",
    "                    print(f\"\\n[System] Connection dropped in '{func.__name__}'. Retrying in {wait_time}s... (Attempt {attempt+1}/{max_retries})\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    # If it's a real code error (e.g., TypeError), crash immediately\n",
    "                    raise e\n",
    "                    \n",
    "        raise Exception(f\"Max retries ({max_retries}) reached. The server is persistently unavailable.\")\n",
    "        \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeRetrieverTool(Tool):\n",
    "    name = \"retrieve_recipe\"\n",
    "    description = \"Retrieves the best matching recipe/s from the database. Returns raw title and ingredients.\"\n",
    "    inputs = {\n",
    "        \"query\": {\"type\": \"string\", \"description\": \"Dish name or ingredients.\"},\n",
    "    }\n",
    "    \n",
    "    output_type = \"string\"\n",
    "    \n",
    "    def __init__(self, k: int = 1, **kwargs):\n",
    "        \"\"\"Initialize the recipe retrieval tool.\n",
    "        \n",
    "        Args:\n",
    "            k: Number of top recipes to retrieve (default: 1)\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.k = k\n",
    "        \n",
    "        print(f\"Loading recipe retrieval system with top {k} results\")\n",
    "        \n",
    "        # Load metadata from embeddings file\n",
    "        self.metadata = []\n",
    "        with open('recipes_for_embeddings.jsonl', 'r') as f:\n",
    "            for line in f:\n",
    "                self.metadata.append(json.loads(line))\n",
    "        \n",
    "        # Load full recipe details (with ingredients and directions)\n",
    "        with open('full_format_recipes.json', 'r') as f:\n",
    "            full_recipes = json.load(f)\n",
    "        \n",
    "        # HashTable for optimized lookup\n",
    "        self.recipe_lookup = {r.get('title', '').strip(): r for r in full_recipes if r.get('title')}\n",
    "        \n",
    "        # Load embedding model\n",
    "        print(\"Loading embedding model BAAI/bge-m3...\")\n",
    "        self.embed_model = SentenceTransformer('BAAI/bge-m3')\n",
    "        \n",
    "        # Load FAISS index\n",
    "        print(\"Loading FAISS index...\")\n",
    "        self.index = faiss.read_index('recipe_index.faiss')\n",
    "        \n",
    "        print(f\"âœ“ Recipe retrieval system loaded: {len(self.metadata)} recipes indexed\")\n",
    "    @robust_llm_call # Decorator to retry on connection errors\n",
    "    def forward(self, query: str) -> str:\n",
    "        \"\"\"Search for recipes matching the query.\n",
    "        \n",
    "        Args:\n",
    "            query: Natural language search query\n",
    "            \n",
    "        Returns:\n",
    "            Formatted string with recipe titles, ingredients, and directions\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            if not query or not isinstance(query, str):\n",
    "                return \"Found 0 recipes.\"\n",
    "            # 1. Embed the Query and Ensure Float 32 (Required by FAISS)\n",
    "            query_vec = self.embed_model.encode([query], convert_to_tensor=False)\n",
    "            query_vec = np.array(query_vec).astype('float32')\n",
    "            \n",
    "            # 2. Normalize euclidean distance\n",
    "            faiss.normalize_L2(query_vec)\n",
    "            \n",
    "            # 3. Search\n",
    "            _, indices = self.index.search(query_vec, self.k)\n",
    "            \n",
    "            # 4. Retrieve\n",
    "            retrieved_docs = [self.metadata[idx] for idx in indices[0] if idx != -1]\n",
    "            \n",
    "            # 5. Format Output\n",
    "            output = f\"Found {len(retrieved_docs)} recipes matching '{query}':\\n\\n\"\n",
    "            \n",
    "            for i, doc in enumerate(retrieved_docs, 1):\n",
    "                title = doc['title'].strip()\n",
    "                full_recipe = self.recipe_lookup.get(title)\n",
    "                \n",
    "                output += f\"{'='*40} Recipe {i} {'='*40}\\n\"\n",
    "                output += f\"TITLE: {title}\\n\"\n",
    "                \n",
    "                if full_recipe:\n",
    "                    output += \"INGREDIENTS:\\n\" + \"\\n\".join([f\" - {ing}\" for ing in full_recipe.get('ingredients', [])])\n",
    "                    output += \"\\n\\nDIRECTIONS:\\n\" + \"\\n\".join([f\" {j}. {step}\" for j, step in enumerate(full_recipe.get('directions', []), 1)])\n",
    "                else:\n",
    "                    # Fallback\n",
    "                    output += f\"SUMMARY: {doc.get('text_for_embedding', 'No details available')}\"\n",
    "                \n",
    "                output += \"\\n\\n\"\n",
    "                \n",
    "            return output\n",
    "        except Exception as e:\n",
    "            return f\"Found 0 recipes. Error during retrieval: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a868e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeAdapterTool(Tool):\n",
    "    name = \"adapt_recipe\"\n",
    "    description = \"Rewrites a recipe to comply with a specific dietary constraint (e.g., 'Make this vegan').\"\n",
    "    inputs = {\n",
    "        \"recipe_text\": {\"type\": \"string\", \"description\": \"The original recipe text.\"},\n",
    "        \"target_diet\": {\"type\": \"string\", \"description\": \"The target diet (e.g., 'vegan', 'gluten-free').\"}\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, model_engine, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model_engine = model_engine\n",
    "    @robust_llm_call # Decorator to retry on connection errors\n",
    "    def forward(self, recipe_text: str, target_diet: str) -> str:\n",
    "        # We construct a prompt for the LLM to do the rewriting\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert chef. Rewrite the following recipe to be strictly {target_diet}.\n",
    "        \n",
    "        Rules:\n",
    "        1. Replace ONLY forbidden ingredients with best culinary substitutes.\n",
    "        2. Keep the original formatting.\n",
    "        3. Do not change the dish identity (e.g., 'Beef Stew' becomes 'Lentil Stew', not 'Salad').\n",
    "        \n",
    "        Original Recipe:\n",
    "        {recipe_text}\n",
    "        \n",
    "        Rewritten Recipe:\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call the LLM (using smolagents' model wrapper)\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        # fixed to return content instead of whole message for validation\n",
    "        response = self.model_engine(messages)\n",
    "        if hasattr(response, \"content\"):\n",
    "            return response.content\n",
    "        else:\n",
    "            return str(response)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeValidatorTool(Tool):\n",
    "    name = \"validate_recipe\"\n",
    "    description = \"Checks recipe compliance. Returns strictly 'PASS' or 'FAIL'.\"\n",
    "    inputs = {\n",
    "        \"recipe_text\": {\"type\": \"string\", \"description\": \"The recipe text.\"},\n",
    "        \"constraint\": {\"type\": \"string\", \"description\": \"The diet (e.g., 'vegan').\"}\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, model_engine, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model_engine = model_engine\n",
    "\n",
    "    @robust_llm_call\n",
    "    def forward(self, recipe_text: str, constraint: str) -> str:\n",
    "        prompt = f\"\"\"\n",
    "        Review this recipe for the strict constraint: \"{constraint}\".\n",
    "        RECIPE: {recipe_text[:3000]} # Truncate to avoid context errors\n",
    "        \n",
    "        If ANY forbidden ingredient is present, output FAIL.\n",
    "        If it is safe, output PASS.\n",
    "        \n",
    "        Final Answer (Strictly 'PASS' or 'FAIL'):\n",
    "        \"\"\"\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        try:\n",
    "            response = self.model_engine(messages)\n",
    "            content = response.content if hasattr(response, \"content\") else str(response)\n",
    "            \n",
    "            # Deterministic Parsing\n",
    "            if \"FAIL\" in content.upper():\n",
    "                return \"FAIL\"\n",
    "            return \"PASS\"\n",
    "        except Exception:\n",
    "            # Fallback to FAIL on model error to be safe\n",
    "            return \"FAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6dced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "\n",
    "class WebSearchTool(Tool):\n",
    "    name = \"duckduckgo_search\"\n",
    "    description = \"Searches the web for recipes. Returns the content of the best result as a string.\"\n",
    "    inputs = {\n",
    "        \"query\": {\"type\": \"string\", \"description\": \"Search query.\"}\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        try:\n",
    "            results = DDGS().text(query, max_results=3)\n",
    "            if not results:\n",
    "                return \"No recipes found on the web.\"\n",
    "            \n",
    "            # Format the list of results into a single string for the Agent\n",
    "            formatted_results = \"Web Search Results:\\n\"\n",
    "            for res in results:\n",
    "                formatted_results += f\"TITLE: {res['title']}\\nCONTENT: {res['body']}\\nURL: {res['href']}\\n\\n\"\n",
    "            \n",
    "            return formatted_results\n",
    "        except Exception as e:\n",
    "            return f\"Web search failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50084c06",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d85758",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InferenceClientModel(model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde19112",
   "metadata": {},
   "source": [
    "# Instantiate the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e243640",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = RecipeRetrieverTool()\n",
    "adapter_tool = RecipeAdapterTool(model_engine=model)\n",
    "validator_tool = RecipeValidatorTool(model_engine=model)\n",
    "search_tool = WebSearchTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66278aa3",
   "metadata": {},
   "source": [
    "# Define prompt for the multiagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an intelligent Culinary Agent powered by Qwen-72B.\n",
    "Your goal is to find, adapt, and validate recipes programmatically.\n",
    "\n",
    "AVAILABLE TOOLS:\n",
    "1. `retrieve_recipe(query)`: Searches internal DB. Returns a formatted STRING.\n",
    "2. `adapt_recipe(recipe_text, target_diet)`: Rewrites the recipe text. Returns a STRING.\n",
    "3. `validate_recipe(recipe_text, constraint)`: Checks compliance. Returns strictly \"PASS\" or \"FAIL\".\n",
    "4. `duckduckgo_search(query)`: Web search fallback. Returns a STRING.\n",
    "\n",
    "### CRITICAL CODING RULES (VIOLATION = CRASH)\n",
    "1. **NO BACKSLASHES (`\\\\`)**:\n",
    "   - Use parentheses `()` for long function calls.\n",
    "\n",
    "2. **NO PASSIVE PRINTING**:\n",
    "   - **RIGHT:** `if validate_recipe(...) == \"FAIL\":`\n",
    "   - **REASON:** Handle logical flows in code.\n",
    "\n",
    "3. **VARIABLE SAFETY**:\n",
    "   - **STATELESS EXECUTION**: Your variables do NOT persist between turns.\n",
    "   - **ALWAYS** initialize `recipe_candidate = None` at the start of your code.\n",
    "   - **NEVER** copy-paste massive recipe text unless absolutely necessary (keeps code clean).\n",
    "\n",
    "### STANDARD OPERATING PROCEDURE (SOP):\n",
    "\n",
    "1. **SETUP**:\n",
    "   - Initialize: `recipe_candidate = None`\n",
    "   - Define `search_query` based on the user's request.\n",
    "   - Define `target_diet` (e.g., \"vegan\", \"keto\").\n",
    "\n",
    "2. **ACQUISITION**:\n",
    "   - Call `recipe_candidate = retrieve_recipe(search_query)`.\n",
    "   \n",
    "   - **Check for Failure**:\n",
    "       # If retriever returns empty/short text or \"Found 0\", fallback to Web\n",
    "       if not recipe_candidate or len(recipe_candidate) < 100 or \"Found 0\" in recipe_candidate:\n",
    "           recipe_candidate = duckduckgo_search(f\"{search_query} recipe {target_diet}\")\n",
    "\n",
    "3. **VALIDATION & REPAIR**:\n",
    "   - Call `status = validate_recipe(recipe_candidate, constraint=target_diet)`.\n",
    "   \n",
    "   - **IF** `status == \"FAIL\"`:\n",
    "       # Adapt the recipe\n",
    "       recipe_candidate = adapt_recipe(recipe_text=recipe_candidate, target_diet=target_diet)\n",
    "       final_answer(recipe_candidate)\n",
    "   \n",
    "   - **ELSE**:\n",
    "       final_answer(recipe_candidate)\n",
    "\n",
    "4. **FINAL SUBMISSION**:\n",
    "   - Ensure `final_answer` is executed in all paths.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "- Strict Python code block.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d3ed0f",
   "metadata": {},
   "source": [
    "# Instantiate the multiagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14993ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(\n",
    "    tools=[\n",
    "        retriever_tool, \n",
    "        adapter_tool, \n",
    "        validator_tool, \n",
    "        search_tool\n",
    "    ],\n",
    "    model=model,\n",
    "    add_base_tools=True, # This enables the \"scratchpad\" where Qwen writes its Python logic\n",
    "    max_steps=12, # Give it enough turns to think -> adapt -> validate\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31464bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_safe(agent, prompt):\n",
    "    \"\"\"\n",
    "    Retries the AGENT'S BRAIN (Planning/Reasoning) if the server fails.\n",
    "    \"\"\"\n",
    "    max_retries = 5\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return agent.run(prompt)\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            if \"503\" in error_msg or \"Service Temporarily Unavailable\" in error_msg or \"404\" in error_msg:\n",
    "                wait_time = 2 ** (attempt + 1)\n",
    "                print(f\"\\nðŸ§  Agent 'Brain' glitch (Attempt {attempt+1}/{max_retries}). Retrying decision in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                raise e # Real error, let it crash\n",
    "    raise Exception(\"Agent Brain failed. Server is down.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62146af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = run_agent(\"I need a high protein recipe that includes chicken.\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20771bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@robust_llm_call # handle random sever disconnects\n",
    "def start_session():\n",
    "    # 1 get the initial query from the user\n",
    "    \n",
    "    \n",
    "    current_recipe_context = None\n",
    "    if os.path.exists(\"last_recipe_state.txt\"):\n",
    "        print(\"found previous session! Loading last recipe...\")\n",
    "        with open(\"last_recipe_state.txt\", \"r\") as f:\n",
    "            current_recipe_context = f.read()\n",
    "            print(f\"RESUMED CONTEXT: {current_recipe_context[:100]}...\")\n",
    "\n",
    "    user_request = input(\"\\nEnter your food request (or 'clear' to start fresh): \")\n",
    "    \n",
    "    if user_request.lower() == 'clear':\n",
    "        current_recipe_context = None\n",
    "        if os.path.exists(\"last_recipe_state.txt\"): os.remove(\"last_recipe_state.txt\")\n",
    "        user_request = input(\"Enter new food request: \")\n",
    "\n",
    "\n",
    "    while True:\n",
    "        # (Construct prompt as before...)\n",
    "        if not current_recipe_context:\n",
    "            full_prompt = f\"{SYSTEM_PROMPT}\\nUSER REQUEST: {user_request}\"\n",
    "        else:\n",
    "            full_prompt = f\"\"\"\n",
    "            {SYSTEM_PROMPT}\n",
    "            CONTEXT: Previous recipe provided.\n",
    "            PREVIOUS RECIPE: {current_recipe_context}\n",
    "            USER FEEDBACK: {user_request}\n",
    "            TASK: Adapt PREVIOUS RECIPE to USER FEEDBACK. Validate it.\n",
    "            \"\"\"\n",
    "        \n",
    "        print(\"\\n--- Agent is thinking... ---\\n\")\n",
    "\n",
    "        try:\n",
    "            # Run the agent\n",
    "            response = run_agent_safe(agent, full_prompt)\n",
    "            \n",
    "            # --- SAVE STATE IMMEDIATELY FOR HANDLING SERVER DISCONNECT ---\n",
    "            current_recipe_context = response\n",
    "            with open(\"last_recipe_state.txt\", \"w\") as f:\n",
    "                f.write(str(response))\n",
    "            # ------------------------------\n",
    "\n",
    "            print(f\"\\n[AGENT]:\\n{response}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL ERROR: {e}\")\n",
    "            print(\"The agent state has been preserved. You can try running the cell again.\")\n",
    "            break \n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        user_request = input(\"Feedback (or type 'exit'): \")\n",
    "        if user_request.lower() in ['exit', 'quit', 'q']:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd82e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8644a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meal_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
