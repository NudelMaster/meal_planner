{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19502211",
   "metadata": {},
   "source": [
    "# Meal Planner Recipe Preprocessing\n",
    "\n",
    "This notebook cleans and enriches the raw recipe dataset so it can be reused across projects. It performs the following steps:\n",
    "\n",
    "- load the raw CSV hosted on Hugging Face (Edamam-based recipe dataset)\n",
    "- extract convenient nutrient totals (fat, carbs, protein)\n",
    "- normalize label and ingredient fields for easier downstream filtering\n",
    "- drop obviously invalid rows and save a processed CSV ready for analysis or app ingestion\n",
    "\n",
    "Update the configuration section below if your raw file lives elsewhere or you want a different output path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d1d0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing cell added: config loaded\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing config and imports\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Input/Output paths\n",
    "INPUT_JSON = \"full_format_recipes.json\"\n",
    "OUTPUT_JSONL = \"recipes_for_embeddings.jsonl\"\n",
    "OUTPUT_CSV = \"recipes_processed_for_embeddings.csv\"\n",
    "MAX_EMBED_TEXT_CHARS = 2000\n",
    "\n",
    "print('Preprocessing cell added: config loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b5df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: normalization, canonical key, synthesis\n",
    "def _normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s\\-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def normalize_ingredient_token(tok: str) -> str:\n",
    "    tok = str(tok)\n",
    "    tok = tok.strip().lower()\n",
    "    tok = re.sub(r\"\\([^)]*\\)\", \"\", tok)  # remove parentheses\n",
    "    tok = re.sub(r\"\\d+\\/\\d+|\\d+\\.\\d+|\\d+\", \"\", tok)  # remove numbers/fractions\n",
    "    tok = re.sub(r\"\\b(cups?|cup|tablespoons?|tbsp|teaspoons?|tsp|grams?|g|kg|ounces?|oz|pounds?|lb|pinch|slice|slices)\\b\", \"\", tok)\n",
    "    tok = re.sub(r\"[^a-z0-9\\s\\-]\", \"\", tok)\n",
    "    tok = re.sub(r\"\\s+\", \" \", tok)\n",
    "    return tok.strip()\n",
    "\n",
    "\n",
    "def normalize_ingredients(val) -> list:\n",
    "    if val is None or (isinstance(val, float) and pd.isna(val)):\n",
    "        return []\n",
    "    if isinstance(val, list):\n",
    "        tokens = [normalize_ingredient_token(x) for x in val if x and str(x).strip()]\n",
    "    else:\n",
    "        # conservative split on comma when a list isn't available\n",
    "        tokens = [normalize_ingredient_token(x) for x in str(val).split(',') if x and x.strip()]\n",
    "    tokens = [t for t in tokens if t]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def canonical_key(title, ingredients_list):\n",
    "    norm_title = _normalize_text(title)\n",
    "    norm_ing_sorted = sorted(set([_normalize_text(x) for x in ingredients_list if x]))\n",
    "    return norm_title + ' || ' + ' | '.join(norm_ing_sorted)\n",
    "\n",
    "\n",
    "def synthesize_title_from_ingredients(ings):\n",
    "    if not ings:\n",
    "        return \"\"\n",
    "    # use first meaningful ingredient tokens as fallback title\n",
    "    return (ings[0].title()) if isinstance(ings[0], str) else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89734553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 20130; after drop: 20111; after dedupe: 18222; final saved: 18222\n",
      "Sample entries:\n",
      "[{'title': '\"Adult\" Pimiento Cheese ', 'text_for_embedding': '\"Adult\" Pimiento Cheese. Ingredients: a - jar diced pimientos, coarsely grated sharp cheddar, crackers, crudits, or large garlic cloves, to mayonnaise, toasted baguette'}, {'title': '\"Blanketed\" Eggplant ', 'text_for_embedding': '\"Blanketed\" Eggplant. Ingredients: drained capers, dried oregano, extra-virgin olive oil, fresh basil leaves, large fresh mint leaves, large garlic cloves slivered flattened, medium onion chopped, olive oil, small japanese eggplants peeled, tomatoes'}, {'title': '\"Bloody Mary\" Tomato Toast with Celery and Horseradish ', 'text_for_embedding': '\"Bloody Mary\" Tomato Toast with Celery and Horseradish. Ingredients: cayenne pepper, celery stalks thinly sliced, coarsely chopped celery leaves, extra-virgin olive oil, finely grated fresh horseradish divided, freshly ground black pepper, grape tomatoes halved, kosher salt, lemon zested juiced, mayonnaise, shallot finely chopped, sherry vinegar, toasted rye bread, worcestershire sauce'}, {'title': '\"Brown on Blonde\" Blondies ', 'text_for_embedding': '\"Brown on Blonde\" Blondies. Ingredients: all-purpose flour, almond butter, baking powder, dark brown sugar, kosher salt, large egg yolk, large eggs, pecans, unsalted butter, vanilla extract, walnuts'}, {'title': '\"California Roll\" Salad ', 'text_for_embedding': '\"California Roll\" Salad. Ingredients: available at asian markets natural foods stores and some supermarkets, avocado, cold water, finely chopped pickled ginger, finely shredded carrot, ginger juice, hot water, large seedless cucumber quartered lengthwise cored and, long-grain rice, plus rice vinegar, salt, scallions cut lengthwise into thin -inch strips, sesame seeds, sheets nori, soy sauce, sugar, surimi if desired sliced thin, vegetable oil, wasabi powder'}]\n"
     ]
    }
   ],
   "source": [
    "# Run preprocessing: apply normalization, handle missing, dedupe, save outputs\n",
    "\n",
    "with open(INPUT_JSON, \"r\") as f:\n",
    "    epicurious_raw = json.load(f)\n",
    "    \n",
    "df = pd.DataFrame(epicurious_raw)\n",
    "before_count = len(df)\n",
    "\n",
    "# Ensure ingredients column is normalized to lists\n",
    "if 'ingredients' not in df.columns:\n",
    "    df['ingredients'] = [[] for _ in range(len(df))]\n",
    "else:\n",
    "    df['ingredients'] = df['ingredients'].apply(normalize_ingredients)\n",
    "\n",
    "# Normalize titles and synthesize when missing\n",
    "if 'title' not in df.columns:\n",
    "    df['title'] = ['' for _ in range(len(df))]\n",
    "\n",
    "# Fill NaNs\n",
    "df['title'] = df['title'].fillna('')\n",
    "\n",
    "# Synthesize title when missing but ingredients present\n",
    "missing_title_mask = df['title'].str.strip() == ''\n",
    "has_ings_mask = df['ingredients'].map(len) > 0\n",
    "synth_count = missing_title_mask & has_ings_mask\n",
    "if synth_count.any():\n",
    "    df.loc[synth_count, 'title'] = df.loc[synth_count, 'ingredients'].apply(synthesize_title_from_ingredients)\n",
    "\n",
    "# Drop rows missing both title and ingredients\n",
    "keep_mask = ~((df['title'].str.strip() == '') & (df['ingredients'].map(len) == 0))\n",
    "df = df[keep_mask].copy()\n",
    "\n",
    "# Add normalized fields for deduplication\n",
    "df['norm_title'] = df['title'].apply(_normalize_text)\n",
    "df['norm_ingredients'] = df['ingredients'].apply(lambda lst: sorted(set([_normalize_text(x) for x in lst if x])))\n",
    "\n",
    "df['dedupe_key'] = df.apply(lambda r: r['norm_title'] + ' || ' + ' | '.join(r['norm_ingredients']), axis=1)\n",
    "\n",
    "before_dedupe = len(df)\n",
    "# prefer rows with more ingredients and longer titles\n",
    "df['_ing_count'] = df['norm_ingredients'].apply(len)\n",
    "df['_title_len'] = df['title'].apply(lambda s: len(str(s)))\n",
    "\n",
    "df = df.sort_values(['dedupe_key', '_ing_count', '_title_len'], ascending=[True, False, False])\n",
    "df = df.drop_duplicates('dedupe_key', keep='first')\n",
    "after_dedupe = len(df)\n",
    "\n",
    "# Build text_for_embedding\n",
    "def build_embedding_text(row):\n",
    "    title = str(row['title']).strip()\n",
    "    ings = ', '.join(row['norm_ingredients'])\n",
    "    text = f\"{title}. Ingredients: {ings}\" if ings else title\n",
    "    if len(text) > MAX_EMBED_TEXT_CHARS:\n",
    "        return text[:MAX_EMBED_TEXT_CHARS]\n",
    "    return text\n",
    "\n",
    "df['text_for_embedding'] = df.apply(build_embedding_text, axis=1)\n",
    "\n",
    "# Final filter: ensure non-empty embedding text\n",
    "df = df[df['text_for_embedding'].str.strip() != '']\n",
    "\n",
    "# Save outputs\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "with open(OUTPUT_JSONL, 'w', encoding='utf-8') as f:\n",
    "    for _, r in df[['title', 'text_for_embedding']].iterrows():\n",
    "        json.dump({'title': r['title'], 'text_for_embedding': r['text_for_embedding']}, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f\"Rows before: {before_count}; after drop: {before_dedupe}; after dedupe: {after_dedupe}; final saved: {len(df)}\")\n",
    "\n",
    "# Quick sample check\n",
    "print('Sample entries:')\n",
    "print(df[['title','text_for_embedding']].head(5).to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b3727e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diet_planner_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
