{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09572c27",
   "metadata": {},
   "source": [
    "# Recipe Dataset Preprocessing for RAG\n",
    "\n",
    "This notebook processes recipe data to create a clean, semantically meaningful dataset optimized for Retrieval-Augmented Generation (RAG) systems.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The preprocessing pipeline:\n",
    "1. Loads recipe data from a Parquet file\n",
    "2. Creates a `search_vector` column with clean, semantic text for embedding\n",
    "3. Removes unnecessary columns\n",
    "4. Saves the processed dataset ready for RAG\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- `pyarrow` for reading Parquet files\n",
    "- `pandas` for data manipulation\n",
    "- `numpy` for array handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0da5a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\yefim\\miniforge3\\envs\\diet_planner_ml\\lib\\site-packages (22.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\yefim\\miniforge3\\envs\\diet_planner_ml\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yefim\\miniforge3\\envs\\diet_planner_ml\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yefim\\miniforge3\\envs\\diet_planner_ml\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yefim\\miniforge3\\envs\\diet_planner_ml\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yefim\\miniforge3\\envs\\diet_planner_ml\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yefim\\miniforge3\\envs\\diet_planner_ml\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install pyarrow pandas numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557afd5",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Configure environment and import necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc4c1820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# IMPORTANT: Set environment variable BEFORE importing pyarrow/pandas\n",
    "# This tells pyarrow to ignore Python extension types when reading\n",
    "os.environ['PYARROW_IGNORE_PYTHON_EXTENSION_TYPES'] = '1'\n",
    "\n",
    "# Unregister pandas extension types if they're already registered\n",
    "# This prevents the \"already defined\" error when pandas tries to register them\n",
    "pandas_ext_types = ['pandas.period', 'pandas.interval', 'pandas.nullable_int', \n",
    "                    'pandas.nullable_bool', 'pandas.nullable_float', \n",
    "                    'pandas.nullable_string', 'pandas.nullable_bytes']\n",
    "for ext_name in pandas_ext_types:\n",
    "    try:\n",
    "        pa.unregister_extension_type(ext_name)\n",
    "    except (KeyError, ValueError):\n",
    "        pass  # Extension type not registered, which is fine\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a992c",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Load the recipe dataset from the Parquet file.\n",
    "File is downloaded from url: https://www.kaggle.com/datasets/irkaal/foodcom-recipes-and-reviews?resource=download&select=recipes.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34513166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded successfully\n",
      "  Shape: (522517, 28)\n",
      "  Columns: 28\n",
      "\n",
      "Column names:\n",
      "['RecipeId', 'Name', 'AuthorId', 'AuthorName', 'CookTime', 'PrepTime', 'TotalTime', 'DatePublished', 'Description', 'Images', 'RecipeCategory', 'Keywords', 'RecipeIngredientQuantities', 'RecipeIngredientParts', 'AggregatedRating', 'ReviewCount', 'Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', 'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'RecipeServings', 'RecipeYield', 'RecipeInstructions']\n"
     ]
    }
   ],
   "source": [
    "# Load the recipe dataset\n",
    "df = pd.read_parquet(\"recipes.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "print(f\"✓ Dataset loaded successfully\")\n",
    "print(f\"  Shape: {df.shape}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7814f3",
   "metadata": {},
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "Quick exploration of the dataset structure and data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "affdfadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522517 entries, 0 to 522516\n",
      "Data columns (total 28 columns):\n",
      " #   Column                      Non-Null Count   Dtype              \n",
      "---  ------                      --------------   -----              \n",
      " 0   RecipeId                    522517 non-null  float64            \n",
      " 1   Name                        522517 non-null  object             \n",
      " 2   AuthorId                    522517 non-null  int32              \n",
      " 3   AuthorName                  522517 non-null  object             \n",
      " 4   CookTime                    439972 non-null  object             \n",
      " 5   PrepTime                    522517 non-null  object             \n",
      " 6   TotalTime                   522517 non-null  object             \n",
      " 7   DatePublished               522517 non-null  datetime64[us, UTC]\n",
      " 8   Description                 522512 non-null  object             \n",
      " 9   Images                      522516 non-null  object             \n",
      " 10  RecipeCategory              521766 non-null  object             \n",
      " 11  Keywords                    522517 non-null  object             \n",
      " 12  RecipeIngredientQuantities  522517 non-null  object             \n",
      " 13  RecipeIngredientParts       522517 non-null  object             \n",
      " 14  AggregatedRating            269294 non-null  float64            \n",
      " 15  ReviewCount                 275028 non-null  float64            \n",
      " 16  Calories                    522517 non-null  float64            \n",
      " 17  FatContent                  522517 non-null  float64            \n",
      " 18  SaturatedFatContent         522517 non-null  float64            \n",
      " 19  CholesterolContent          522517 non-null  float64            \n",
      " 20  SodiumContent               522517 non-null  float64            \n",
      " 21  CarbohydrateContent         522517 non-null  float64            \n",
      " 22  FiberContent                522517 non-null  float64            \n",
      " 23  SugarContent                522517 non-null  float64            \n",
      " 24  ProteinContent              522517 non-null  float64            \n",
      " 25  RecipeServings              339606 non-null  float64            \n",
      " 26  RecipeYield                 174446 non-null  object             \n",
      " 27  RecipeInstructions          522517 non-null  object             \n",
      "dtypes: datetime64[us, UTC](1), float64(13), int32(1), object(13)\n",
      "memory usage: 109.6+ MB\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Sample data types for list columns:\n",
      "RecipeIngredientParts: <class 'numpy.ndarray'>\n",
      "Keywords: <class 'numpy.ndarray'>\n",
      "RecipeInstructions: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Display dataset info\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\" * 80)\n",
    "df.info()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Check data types for list-like columns\n",
    "print(\"\\nSample data types for list columns:\")\n",
    "sample_row = df.iloc[0]\n",
    "print(f\"RecipeIngredientParts: {type(sample_row['RecipeIngredientParts'])}\")\n",
    "print(f\"Keywords: {type(sample_row['Keywords'])}\")\n",
    "print(f\"RecipeInstructions: {type(sample_row['RecipeInstructions'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "399a628d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522517 entries, 0 to 522516\n",
      "Data columns (total 28 columns):\n",
      " #   Column                      Non-Null Count   Dtype              \n",
      "---  ------                      --------------   -----              \n",
      " 0   RecipeId                    522517 non-null  float64            \n",
      " 1   Name                        522517 non-null  object             \n",
      " 2   AuthorId                    522517 non-null  int32              \n",
      " 3   AuthorName                  522517 non-null  object             \n",
      " 4   CookTime                    439972 non-null  object             \n",
      " 5   PrepTime                    522517 non-null  object             \n",
      " 6   TotalTime                   522517 non-null  object             \n",
      " 7   DatePublished               522517 non-null  datetime64[us, UTC]\n",
      " 8   Description                 522512 non-null  object             \n",
      " 9   Images                      522516 non-null  object             \n",
      " 10  RecipeCategory              521766 non-null  object             \n",
      " 11  Keywords                    522517 non-null  object             \n",
      " 12  RecipeIngredientQuantities  522517 non-null  object             \n",
      " 13  RecipeIngredientParts       522517 non-null  object             \n",
      " 14  AggregatedRating            269294 non-null  float64            \n",
      " 15  ReviewCount                 275028 non-null  float64            \n",
      " 16  Calories                    522517 non-null  float64            \n",
      " 17  FatContent                  522517 non-null  float64            \n",
      " 18  SaturatedFatContent         522517 non-null  float64            \n",
      " 19  CholesterolContent          522517 non-null  float64            \n",
      " 20  SodiumContent               522517 non-null  float64            \n",
      " 21  CarbohydrateContent         522517 non-null  float64            \n",
      " 22  FiberContent                522517 non-null  float64            \n",
      " 23  SugarContent                522517 non-null  float64            \n",
      " 24  ProteinContent              522517 non-null  float64            \n",
      " 25  RecipeServings              339606 non-null  float64            \n",
      " 26  RecipeYield                 174446 non-null  object             \n",
      " 27  RecipeInstructions          522517 non-null  object             \n",
      "dtypes: datetime64[us, UTC](1), float64(13), int32(1), object(13)\n",
      "memory usage: 109.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1a9cb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample RecipeIngredientParts: <class 'numpy.ndarray'>\n",
      "Sample Keywords: <class 'numpy.ndarray'>\n",
      "Sample RecipeInstructions: <class 'numpy.ndarray'>\n",
      "\n",
      "First few characters of each:\n",
      "RecipeIngredientParts: ['blueberries' 'granulated sugar' 'vanilla yogurt' 'lemon juice']\n",
      "Keywords: ['Dessert' 'Low Protein' 'Low Cholesterol' 'Healthy' 'Free Of...' 'Summer'\n",
      " 'Weeknight' 'Freezer' 'Easy']\n",
      "RecipeInstructions: ['Toss 2 cups berries with sugar.'\n",
      " 'Let stand for 45 minutes, stirring occasionally.'\n",
      " 'Transfer berry-sugar mixture to food processor.'\n",
      " 'Add yogurt and process until smooth.'\n",
      " \"Strain through fine \n"
     ]
    }
   ],
   "source": [
    "# Inspect data types and sample values for list-like columns\n",
    "import ast\n",
    "import json\n",
    "\n",
    "# Check if columns are stored as strings (JSON) or actual lists\n",
    "sample_row = df.iloc[0]\n",
    "\n",
    "print(\"Sample RecipeIngredientParts:\", type(sample_row['RecipeIngredientParts']))\n",
    "print(\"Sample Keywords:\", type(sample_row['Keywords']))\n",
    "print(\"Sample RecipeInstructions:\", type(sample_row['RecipeInstructions']))\n",
    "print(\"\\nFirst few characters of each:\")\n",
    "print(\"RecipeIngredientParts:\", str(sample_row['RecipeIngredientParts'])[:200])\n",
    "print(\"Keywords:\", str(sample_row['Keywords'])[:200])\n",
    "print(\"RecipeInstructions:\", str(sample_row['RecipeInstructions'])[:200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cacf3",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Functions\n",
    "\n",
    "Define helper functions for data preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "751681a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for RAG\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def safe_eval_list(value):\n",
    "    \"\"\"Safely convert string representation of list to actual list\"\"\"\n",
    "    # Handle numpy arrays (common in parquet files)\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value.tolist() if value.size > 0 else []\n",
    "    \n",
    "    # Handle None or NaN\n",
    "    if safe_isna(value):\n",
    "        return []\n",
    "    \n",
    "    if isinstance(value, list):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            # Try JSON first\n",
    "            parsed = json.loads(value)\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            # Try ast.literal_eval\n",
    "            parsed = ast.literal_eval(value)\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except:\n",
    "            pass\n",
    "        # If it's a string but not a list, return as single-item list\n",
    "        return [value] if value.strip() else []\n",
    "    return []\n",
    "\n",
    "def safe_isna(value):\n",
    "    \"\"\"Safely check if value is NaN, handling arrays and scalars\"\"\"\n",
    "    if value is None:\n",
    "        return True\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value.size == 0\n",
    "    try:\n",
    "        return pd.isna(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def format_time(time_str):\n",
    "    \"\"\"Format time string for search - converts ISO 8601 duration to human-readable format\"\"\"\n",
    "    if safe_isna(time_str):\n",
    "        return \"\"\n",
    "    # Handle empty strings\n",
    "    if not time_str or (isinstance(time_str, str) and not time_str.strip()):\n",
    "        return \"\"\n",
    "    \n",
    "    time_str = str(time_str).strip()\n",
    "    \n",
    "    # Parse ISO 8601 duration format (PT45M, PT24H, PT24H45M, etc.)\n",
    "    if time_str.startswith('PT'):\n",
    "        # Remove PT prefix\n",
    "        duration = time_str[2:]\n",
    "        parts = []\n",
    "        \n",
    "        # Extract hours\n",
    "        hour_match = re.search(r'(\\d+)H', duration)\n",
    "        hours = int(hour_match.group(1)) if hour_match else 0\n",
    "        \n",
    "        # Extract minutes\n",
    "        minute_match = re.search(r'(\\d+)M', duration)\n",
    "        minutes = int(minute_match.group(1)) if minute_match else 0\n",
    "        \n",
    "        # Extract seconds (if present)\n",
    "        second_match = re.search(r'(\\d+)S', duration)\n",
    "        seconds = int(second_match.group(1)) if second_match else 0\n",
    "        \n",
    "        # Format as human-readable\n",
    "        time_parts = []\n",
    "        if hours > 0:\n",
    "            time_parts.append(f\"{hours} hour{'s' if hours != 1 else ''}\")\n",
    "        if minutes > 0:\n",
    "            time_parts.append(f\"{minutes} minute{'s' if minutes != 1 else ''}\")\n",
    "        if seconds > 0 and hours == 0 and minutes == 0:  # Only show seconds if no hours/minutes\n",
    "            time_parts.append(f\"{seconds} second{'s' if seconds != 1 else ''}\")\n",
    "        \n",
    "        if time_parts:\n",
    "            return \" \".join(time_parts)\n",
    "        else:\n",
    "            return \"\"  # Empty duration\n",
    "    \n",
    "    # If not ISO 8601 format, return as-is\n",
    "    return time_str\n",
    "\n",
    "def infer_dietary_tags(ingredients_list, keywords_list):\n",
    "    \"\"\"Infer dietary restrictions/preferences from ingredients and keywords\"\"\"\n",
    "    tags = []\n",
    "    ingredients_text = \" \".join([str(ing).lower() for ing in ingredients_list])\n",
    "    keywords_text = \" \".join([str(kw).lower() for kw in keywords_list])\n",
    "    combined_text = ingredients_text + \" \" + keywords_text\n",
    "    \n",
    "    # Vegetarian/Vegan\n",
    "    meat_keywords = ['chicken', 'beef', 'pork', 'lamb', 'turkey', 'fish', 'seafood', 'meat', 'bacon', 'sausage']\n",
    "    dairy_keywords = ['milk', 'cheese', 'butter', 'cream', 'yogurt', 'dairy']\n",
    "    egg_keywords = ['egg', 'eggs']\n",
    "    \n",
    "    has_meat = any(keyword in combined_text for keyword in meat_keywords)\n",
    "    has_dairy = any(keyword in combined_text for keyword in dairy_keywords)\n",
    "    has_eggs = any(keyword in combined_text for keyword in egg_keywords)\n",
    "    \n",
    "    if not has_meat and not has_dairy and not has_eggs:\n",
    "        tags.append(\"vegan\")\n",
    "    elif not has_meat:\n",
    "        tags.append(\"vegetarian\")\n",
    "    \n",
    "    # Gluten-free\n",
    "    gluten_keywords = ['wheat', 'flour', 'bread', 'pasta', 'gluten']\n",
    "    has_gluten = any(keyword in combined_text for keyword in gluten_keywords)\n",
    "    if not has_gluten or 'gluten-free' in combined_text:\n",
    "        tags.append(\"gluten-free\")\n",
    "    \n",
    "    # Low-carb / Keto\n",
    "    if 'low-carb' in combined_text or 'keto' in combined_text:\n",
    "        tags.append(\"low-carb\")\n",
    "    \n",
    "    # Other common dietary tags\n",
    "    if 'paleo' in combined_text:\n",
    "        tags.append(\"paleo\")\n",
    "    if 'keto' in combined_text:\n",
    "        tags.append(\"keto\")\n",
    "    if 'dairy-free' in combined_text:\n",
    "        tags.append(\"dairy-free\")\n",
    "    \n",
    "    return tags\n",
    "\n",
    "def format_nutrition(row):\n",
    "    \"\"\"Format nutritional information as searchable text\"\"\"\n",
    "    nutrition_parts = []\n",
    "    \n",
    "    if not safe_isna(row['Calories']) and row['Calories'] > 0:\n",
    "        nutrition_parts.append(f\"{int(row['Calories'])} calories\")\n",
    "    \n",
    "    macros = []\n",
    "    if not safe_isna(row['ProteinContent']) and row['ProteinContent'] > 0:\n",
    "        macros.append(f\"{row['ProteinContent']:.1f}g protein\")\n",
    "    if not safe_isna(row['CarbohydrateContent']) and row['CarbohydrateContent'] > 0:\n",
    "        macros.append(f\"{row['CarbohydrateContent']:.1f}g carbs\")\n",
    "    if not safe_isna(row['FatContent']) and row['FatContent'] > 0:\n",
    "        macros.append(f\"{row['FatContent']:.1f}g fat\")\n",
    "    \n",
    "    if macros:\n",
    "        nutrition_parts.append(\", \".join(macros))\n",
    "    \n",
    "    # Dietary restrictions based on content\n",
    "    if not safe_isna(row['SodiumContent']) and row['SodiumContent'] < 500:\n",
    "        nutrition_parts.append(\"low-sodium\")\n",
    "    if not safe_isna(row['SugarContent']) and row['SugarContent'] < 10:\n",
    "        nutrition_parts.append(\"low-sugar\")\n",
    "    if not safe_isna(row['FiberContent']) and row['FiberContent'] > 5:\n",
    "        nutrition_parts.append(\"high-fiber\")\n",
    "    \n",
    "    return \" | \".join(nutrition_parts) if nutrition_parts else \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55596a1",
   "metadata": {},
   "source": [
    "## 5. Create Search Vector\n",
    "\n",
    "Generate a clean, semantically meaningful `search_vector` column optimized for RAG embeddings.\n",
    "\n",
    "The search vector contains:\n",
    "- Recipe name (lowercase)\n",
    "- Semantic tags (category, keywords, dietary info, health descriptors)\n",
    "- Ingredients (cleaned, lowercase, no quantities)\n",
    "\n",
    "**Note:** All numeric metadata (times, calories, grams, servings) and structural labels are removed to focus on semantic meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fed4f19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating search vector column...\n",
      "Search vector created. Sample:\n",
      "low-fat berry blue frozen dessert. frozen desserts; dessert; low protein; low cholesterol; healthy; free of.; summer; weeknight; freezer; easy; vegetarian; gluten-free; low-sodium; low-fat. ingredients include blueberries, granulated sugar, vanilla yogurt, and lemon juice.\n"
     ]
    }
   ],
   "source": [
    "def create_search_vector(row):\n",
    "    \"\"\"Create clean, semantically meaningful search vector for RAG embedding\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # 1. Recipe name (first sentence)\n",
    "    recipe_name = \"\"\n",
    "    if not safe_isna(row['Name']):\n",
    "        recipe_name = str(row['Name']).strip().lower()\n",
    "        parts.append(recipe_name)\n",
    "    \n",
    "    # 2. Collect all semantic tags and descriptors\n",
    "    semantic_tags = []\n",
    "    \n",
    "    # Category\n",
    "    if not safe_isna(row['RecipeCategory']):\n",
    "        category = str(row['RecipeCategory']).strip().lower()\n",
    "        semantic_tags.append(category)\n",
    "    \n",
    "    # Keywords (lowercase, clean)\n",
    "    keywords = safe_eval_list(row['Keywords'])\n",
    "    if keywords:\n",
    "        for kw in keywords:\n",
    "            kw_clean = str(kw).strip().lower()\n",
    "            if kw_clean and kw_clean not in semantic_tags:\n",
    "                semantic_tags.append(kw_clean)\n",
    "    \n",
    "    # Dietary tags (inferred)\n",
    "    ingredients = safe_eval_list(row['RecipeIngredientParts'])\n",
    "    dietary_tags = infer_dietary_tags(ingredients, keywords)\n",
    "    for tag in dietary_tags:\n",
    "        if tag not in semantic_tags:\n",
    "            semantic_tags.append(tag)\n",
    "    \n",
    "    # Health descriptors from nutrition (no numbers, just descriptors)\n",
    "    if not safe_isna(row['SodiumContent']) and row['SodiumContent'] < 500:\n",
    "        if \"low-sodium\" not in semantic_tags:\n",
    "            semantic_tags.append(\"low-sodium\")\n",
    "    if not safe_isna(row['SugarContent']) and row['SugarContent'] < 10:\n",
    "        if \"low-sugar\" not in semantic_tags:\n",
    "            semantic_tags.append(\"low-sugar\")\n",
    "    if not safe_isna(row['FiberContent']) and row['FiberContent'] > 5:\n",
    "        if \"high-fiber\" not in semantic_tags:\n",
    "            semantic_tags.append(\"high-fiber\")\n",
    "    if not safe_isna(row['FatContent']) and row['FatContent'] < 10:\n",
    "        if \"low-fat\" not in semantic_tags:\n",
    "            semantic_tags.append(\"low-fat\")\n",
    "    \n",
    "    # Add semantic tags as second part (semicolon-separated)\n",
    "    if semantic_tags:\n",
    "        parts.append(\"; \".join(semantic_tags))\n",
    "    \n",
    "    # 3. Ingredients (lowercase, no quantities)\n",
    "    if ingredients:\n",
    "        ingredients_lower = [str(ing).strip().lower() for ing in ingredients]\n",
    "        # Remove common quantity words and numbers\n",
    "        cleaned_ingredients = []\n",
    "        for ing in ingredients_lower:\n",
    "            # Remove leading numbers, measurements, etc.\n",
    "            ing_clean = re.sub(r'^\\d+\\s*', '', ing)  # Remove leading numbers\n",
    "            ing_clean = re.sub(r'^\\d+/\\d+\\s*', '', ing_clean)  # Remove fractions\n",
    "            ing_clean = re.sub(r'\\b(cup|cups|tbsp|tsp|oz|lb|g|kg|ml|l|tablespoon|teaspoon|ounce|pound|gram|kilogram|milliliter|liter)\\b', '', ing_clean)\n",
    "            ing_clean = re.sub(r'\\s+', ' ', ing_clean).strip()  # Clean whitespace\n",
    "            if ing_clean:\n",
    "                cleaned_ingredients.append(ing_clean)\n",
    "        \n",
    "        if cleaned_ingredients:\n",
    "            # Format as natural sentence\n",
    "            if len(cleaned_ingredients) == 1:\n",
    "                parts.append(f\"ingredients include {cleaned_ingredients[0]}.\")\n",
    "            elif len(cleaned_ingredients) == 2:\n",
    "                parts.append(f\"ingredients include {cleaned_ingredients[0]} and {cleaned_ingredients[1]}.\")\n",
    "            else:\n",
    "                ingredients_str = \", \".join(cleaned_ingredients[:-1]) + f\", and {cleaned_ingredients[-1]}\"\n",
    "                parts.append(f\"ingredients include {ingredients_str}.\")\n",
    "    \n",
    "    # Join all parts with periods or semicolons (already handled above)\n",
    "    search_text = \". \".join(parts)\n",
    "    \n",
    "    # Clean up: remove multiple spaces, ensure proper punctuation\n",
    "    search_text = re.sub(r'\\.+', '.', search_text)  # Multiple periods to one\n",
    "    search_text = re.sub(r'\\s+', ' ', search_text)  # Multiple spaces to one\n",
    "    search_text = search_text.strip()\n",
    "    \n",
    "    # Ensure it ends with a period\n",
    "    if search_text and not search_text.endswith('.'):\n",
    "        search_text += \".\"\n",
    "    \n",
    "    return search_text\n",
    "\n",
    "# Create a copy for processing\n",
    "df_processed = df.copy()\n",
    "\n",
    "print(\"Creating search vector column...\")\n",
    "df_processed['search_vector'] = df_processed.apply(create_search_vector, axis=1)\n",
    "\n",
    "print(f\"Search vector created. Sample:\")\n",
    "print(df_processed['search_vector'].iloc[0][:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf229e",
   "metadata": {},
   "source": [
    "## 6. Remove Unnecessary Columns\n",
    "\n",
    "Keep only columns needed for RAG and remove metadata that's not useful for semantic search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abd22fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: 28\n",
      "Final columns: 21\n",
      "\n",
      "Removed columns: {'RecipeIngredientQuantities', 'AuthorName', 'AggregatedRating', 'DatePublished', 'RecipeYield', 'AuthorId', 'Images', 'ReviewCount'}\n",
      "\n",
      "Final dataset shape: (522517, 21)\n",
      "\n",
      "Final columns:\n",
      "['RecipeId', 'Name', 'Description', 'RecipeCategory', 'RecipeIngredientParts', 'RecipeInstructions', 'PrepTime', 'CookTime', 'TotalTime', 'RecipeServings', 'Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', 'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'Keywords', 'search_vector']\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns and keep only what's needed for RAG\n",
    "columns_to_keep = [\n",
    "    'RecipeId',           # For identification\n",
    "    'Name',               # Recipe name\n",
    "    'Description',        # Recipe description\n",
    "    'RecipeCategory',     # Category\n",
    "    'RecipeIngredientParts',  # Ingredients list\n",
    "    'RecipeInstructions', # Cooking instructions\n",
    "    'PrepTime',           # Preparation time\n",
    "    'CookTime',           # Cooking time\n",
    "    'TotalTime',          # Total time\n",
    "    'RecipeServings',     # Number of servings\n",
    "    'Calories',           # Nutritional info\n",
    "    'FatContent',\n",
    "    'SaturatedFatContent',\n",
    "    'CholesterolContent',\n",
    "    'SodiumContent',\n",
    "    'CarbohydrateContent',\n",
    "    'FiberContent',\n",
    "    'SugarContent',\n",
    "    'ProteinContent',\n",
    "    'Keywords',           # Keywords/tags\n",
    "    'search_vector'       # The main RAG search column\n",
    "]\n",
    "\n",
    "# Create final dataset\n",
    "df_rag = df_processed[columns_to_keep].copy()\n",
    "\n",
    "print(f\"Original columns: {len(df.columns)}\")\n",
    "print(f\"Final columns: {len(df_rag.columns)}\")\n",
    "print(f\"\\nRemoved columns: {set(df.columns) - set(df_rag.columns)}\")\n",
    "print(f\"\\nFinal dataset shape: {df_rag.shape}\")\n",
    "print(f\"\\nFinal columns:\")\n",
    "print(df_rag.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b105860",
   "metadata": {},
   "source": [
    "## 7. Preview Results\n",
    "\n",
    "Preview a sample of the processed data to verify the search_vector format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07c28c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed row:\n",
      "================================================================================\n",
      "Recipe ID: 38.0\n",
      "Name: Low-Fat Berry Blue Frozen Dessert\n",
      "\n",
      "Search Vector (first 500 chars):\n",
      "low-fat berry blue frozen dessert. frozen desserts; dessert; low protein; low cholesterol; healthy; free of.; summer; weeknight; freezer; easy; vegetarian; gluten-free; low-sodium; low-fat. ingredients include blueberries, granulated sugar, vanilla yogurt, and lemon juice.\n",
      "\n",
      "...\n",
      "\n",
      "Full search vector length: 273 characters\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Preview the processed data\n",
    "print(\"Sample processed row:\")\n",
    "print(\"=\" * 80)\n",
    "sample = df_rag.iloc[0]\n",
    "print(f\"Recipe ID: {sample['RecipeId']}\")\n",
    "print(f\"Name: {sample['Name']}\")\n",
    "print(f\"\\nSearch Vector (first 500 chars):\")\n",
    "print(sample['search_vector'][:500])\n",
    "print(\"\\n...\")\n",
    "print(f\"\\nFull search vector length: {len(sample['search_vector'])} characters\")\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89faa0",
   "metadata": {},
   "source": [
    "## 8. Data Quality Check\n",
    "\n",
    "Verify data quality and completeness of the processed dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "216a05e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Check:\n",
      "Total rows: 522517\n",
      "Rows with search_vector: 522517\n",
      "Rows with empty search_vector: 0\n",
      "Average search_vector length: 248 characters\n",
      "\n",
      "Missing values per column:\n",
      "RecipeServings           182911\n",
      "CookTime                  82545\n",
      "RecipeCategory              751\n",
      "Description                   5\n",
      "RecipeId                      0\n",
      "CholesterolContent            0\n",
      "Keywords                      0\n",
      "ProteinContent                0\n",
      "SugarContent                  0\n",
      "FiberContent                  0\n",
      "CarbohydrateContent           0\n",
      "SodiumContent                 0\n",
      "Calories                      0\n",
      "SaturatedFatContent           0\n",
      "FatContent                    0\n",
      "Name                          0\n",
      "TotalTime                     0\n",
      "PrepTime                      0\n",
      "RecipeInstructions            0\n",
      "RecipeIngredientParts         0\n",
      "search_vector                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data quality\n",
    "print(\"Data Quality Check:\")\n",
    "print(f\"Total rows: {len(df_rag)}\")\n",
    "print(f\"Rows with search_vector: {df_rag['search_vector'].notna().sum()}\")\n",
    "print(f\"Rows with empty search_vector: {(df_rag['search_vector'] == '').sum()}\")\n",
    "print(f\"Average search_vector length: {df_rag['search_vector'].str.len().mean():.0f} characters\")\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(df_rag.isnull().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9b83b",
   "metadata": {},
   "source": [
    "## 9. Save Processed Dataset\n",
    "\n",
    "Save the processed dataset to a new Parquet file for use in RAG systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24160e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved to: recipes_rag_ready.parquet\n",
      "File size: 290.06 MB\n",
      "\n",
      "Dataset is ready for RAG! Use the 'search_vector' column for semantic search.\n"
     ]
    }
   ],
   "source": [
    "# Save the processed dataset for RAG\n",
    "output_file = \"recipes_rag_ready.parquet\"\n",
    "df_rag.to_parquet(output_file, engine='pyarrow', index=False)\n",
    "print(f\"Processed dataset saved to: {output_file}\")\n",
    "print(f\"File size: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")\n",
    "print(f\"\\nDataset is ready for RAG! Use the 'search_vector' column for semantic search.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f803633",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What Was Done\n",
    "\n",
    "1. **Created `search_vector` column**: A clean, semantically meaningful text field containing:\n",
    "   - Recipe name (lowercase)\n",
    "   - Semantic tags (category, keywords, dietary restrictions, health descriptors)\n",
    "   - Ingredients (cleaned, lowercase, quantities removed)\n",
    "\n",
    "2. **Removed unnecessary columns**:\n",
    "   - AuthorId, AuthorName (not needed for search)\n",
    "   - DatePublished (not relevant for recipe search)\n",
    "   - Images (not needed for text-based RAG)\n",
    "   - RecipeIngredientQuantities (redundant)\n",
    "   - RecipeYield (redundant with RecipeServings)\n",
    "   - AggregatedRating, ReviewCount (not needed for search)\n",
    "\n",
    "3. **Kept essential columns** for:\n",
    "   - Recipe identification (RecipeId)\n",
    "   - Display (Name, Description, RecipeCategory)\n",
    "   - Ingredients and instructions (for full recipe display)\n",
    "   - Nutritional data (for filtering and display)\n",
    "   - Time information (for filtering)\n",
    "   - Keywords (for additional metadata)\n",
    "\n",
    "### The `search_vector` Column\n",
    "\n",
    "The search vector is optimized for semantic embedding and enables:\n",
    "- **Ingredient-based queries**: \"recipes with chicken and tomatoes\"\n",
    "- **Dietary restrictions**: \"vegan recipes\", \"gluten-free desserts\"\n",
    "- **Health descriptors**: \"low-sodium\", \"high-fiber\", \"low-fat\"\n",
    "- **Category/Cuisine**: \"Italian pasta recipes\", \"breakfast recipes\"\n",
    "- **Combined queries**: \"vegan high-protein quick meals\"\n",
    "\n",
    "All numeric metadata (times, calories, grams, servings) and structural labels are removed to focus purely on semantic meaning for better embedding quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d7a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diet_planner_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
