{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42621d9b",
   "metadata": {},
   "source": [
    "# Get necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a173d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import json\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f5d4a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 'recipes_for_embeddings.jsonl'...\n",
      "Loaded 18222 documents.\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "print(f\"Loading data from 'recipes_for_embeddings.jsonl'...\")\n",
    "assert os.path.exists('recipes_for_embeddings.jsonl'), \"Data file not found!\"\n",
    "with open('recipes_for_embeddings.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "metadata = [d for d in data]  # Keep full object to pass to Qwen later\n",
    "print(f\"Loaded {len(data)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0b8491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Loading FAISS index...\n",
      "Index loaded with 18222 vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model (must match the one used in build_index.ipynb)\n",
    "print(\"Loading embedding model...\")\n",
    "embed_model = SentenceTransformer('BAAI/bge-m3')\n",
    "\n",
    "# Load FAISS index\n",
    "print(\"Loading FAISS index...\")\n",
    "index = faiss.read_index('recipe_index.faiss')\n",
    "print(f\"Index loaded with {index.ntotal} vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95f418d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RETRIEVAL FUNCTION ---\n",
    "def search(query, k=3):\n",
    "    # 1. Embed the query\n",
    "    query_vec = embed_model.encode([query], convert_to_tensor=False)\n",
    "    \n",
    "    # 2. Search FAISS\n",
    "    _, indices = index.search(query_vec, k)\n",
    "    \n",
    "    # 3. Retrieve actual documents\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        results.append(metadata[idx])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628b14d",
   "metadata": {},
   "source": [
    "# Instantiating model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e67252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d024836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rag_response(user_query):\n",
    "    # 1. Retrieve Context\n",
    "    retrieved_docs = search(user_query, k=3)\n",
    "    \n",
    "    # 2. Format Context for the Prompt\n",
    "    context_str = \"\"\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        context_str += f\"Recipe {i+1}: {doc['title']}\\nContent: {doc['text_for_embedding']}\\n\\n\"\n",
    "\n",
    "    # 3. Construct Qwen Chat Template\n",
    "    # Qwen performs best with a clear distinction between system instructions and context\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":\n",
    "         \"You are a helpful, health-conscious AI cooking assistant. \"\n",
    "         \"IMPORTANT: Only use information from the provided recipe context. \"\n",
    "         \"Always cite which recipe(s) you're referencing by name. \"\n",
    "         \"If the answer is not in the context, explicitly say 'I don't have this information in the available recipes.' \"\n",
    "         \"Do not make up recipes or ingredients that aren't in the context.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context:\\n{context_str}\\n\\nQuestion: {user_query}\"}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # 4. Display retrieved recipes for manual validation\n",
    "    print(\"=== RETRIEVED RECIPES ===\")\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        print(f\"{i+1}. {doc['title']}\")\n",
    "    print(\"=========================\\n\")\n",
    "    \n",
    "    # 5. Generate (Mock call if model not loaded)\n",
    "    print(\"--- INPUT PROMPT ---\")\n",
    "    print(text)\n",
    "    print(\"--------------------\")\n",
    "    \n",
    "    return retrieved_docs  # Return for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1be176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_response(llm_response, retrieved_docs):\n",
    "    \"\"\"\n",
    "    Check if the LLM response uses information from retrieved documents\n",
    "    \"\"\"\n",
    "    # Extract recipe titles from retrieved docs\n",
    "    retrieved_titles = [doc['title'].lower() for doc in retrieved_docs]\n",
    "    \n",
    "    # Extract all ingredients from retrieved docs\n",
    "    all_ingredients = set()\n",
    "    for doc in retrieved_docs:\n",
    "        # Parse ingredients from text_for_embedding\n",
    "        text = doc['text_for_embedding'].lower()\n",
    "        if 'ingredients:' in text:\n",
    "            ing_section = text.split('ingredients:')[1].split('recipe:')[0]\n",
    "            all_ingredients.update(ing_section.split(','))\n",
    "    \n",
    "    all_ingredients = {ing.strip() for ing in all_ingredients if ing.strip()}\n",
    "    \n",
    "    print(\"\\n=== VALIDATION ===\")\n",
    "    print(f\"Retrieved Recipes: {retrieved_titles}\")\n",
    "    print(f\"Available Ingredients: {list(all_ingredients)[:10]}...\")  # Show first 10\n",
    "    \n",
    "    # Check if response mentions retrieved recipes\n",
    "    llm_lower = llm_response.lower()\n",
    "    mentioned_recipes = [title for title in retrieved_titles if title in llm_lower]\n",
    "    \n",
    "    if mentioned_recipes:\n",
    "        print(f\"✓ Response cites: {mentioned_recipes}\")\n",
    "    else:\n",
    "        print(\"⚠ WARNING: Response doesn't cite any retrieved recipes!\")\n",
    "    \n",
    "    print(\"==================\\n\")\n",
    "    \n",
    "    return {\n",
    "        'retrieved_titles': retrieved_titles,\n",
    "        'mentioned_recipes': mentioned_recipes,\n",
    "        'likely_grounded': len(mentioned_recipes) > 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42b5d9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INPUT PROMPT ---\n",
      "<|im_start|>system\n",
      "You are a helpful, health-conscious AI cooking assistant.You specialize in generating, adapting, and evaluating recipes based on user dietary needs and available ingredients.Think step-by-step and provide clear, friendly responses<|im_end|>\n",
      "<|im_start|>user\n",
      "Context:\n",
      "Recipe 1: Roasted Eggplant and Garlic Dip \n",
      "Content: Ingredients: eggplant, extra-virgin olive oil, red-wine vinegar or to taste, small heads garlic. Recipe: Roasted Eggplant and Garlic Dip\n",
      "\n",
      "Recipe 2: Herbed Eggplant with Tomatoes, Onion and Garlic \n",
      "Content: Ingredients: canned diced tomatoes in juice drained, chopped fresh parsley, chopped white onion, dried oregano, extra-virgin olive oil, fresh lemon juice, garlic cloves minced, medium eggplants, pita bread cut into wedges, plain yogurt, red wine vinegar. Recipe: Herbed Eggplant with Tomatoes, Onion and Garlic\n",
      "\n",
      "Recipe 3: Garlicky Eggplant Salad \n",
      "Content: Ingredients: chopped fresh oregano, chopped fresh oregano or dried crumbled, fresh lemon juice, ground cumin, large eggplants, large garlic cloves slivered, olive oil, pita bread, red leaf lettuce, tomatoes sliced. Recipe: Garlicky Eggplant Salad\n",
      "\n",
      "\n",
      "\n",
      "Question: I have eggplants and garlic, what can I make?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"I have eggplants and garlic, what can I make?\"\n",
    "generate_rag_response(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe7a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meal_planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
